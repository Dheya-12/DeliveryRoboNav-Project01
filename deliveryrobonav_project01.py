# -*- coding: utf-8 -*-
"""DeliveryRoboNav-Project01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FtMEhy8IJshjmmoPnTCg2t0IUYUGtoZg
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sb
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score,classification_report, confusion_matrix
import matplotlib.pyplot as plt
# %matplotlib inline

"""adding headers to all the 24 sensors and the class variable

"""

df=pd.read_csv('/content/sensor_readings_24.csv', header=None)
headerList = ['S1','S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21' ,'S22', 'S23', 'S24','class'  ]
df.to_csv("newsensor_readings_24.csv", header=headerList, index=False)
df2 = pd.read_csv("newsensor_readings_24.csv")

df2

df2.info()

df2.describe()

df2.shape

df2.isnull().sum()

sb.pairplot(df2,hue='class')

sb.heatmap(df2.corr())
plt.show()

"""assigning input attributes and output attributes separately"""

X=df2.drop(['class'],axis=1)
y=df2['class']

"""#Now logistic regression"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5)##50:50 train:test ratio
logistic = LogisticRegression()
logistic.fit(X_train,y_train)
y_predict = logistic.predict(X_test)
y_predict = logistic.predict(X_test)

print('Accuracy:',accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

plt.figure(figsize=(4,4))
sb.heatmap(confusion_matrix(y_test,y_predict), annot=True, fmt=".1f", linewidths=.90, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_predict))
plt.title(all_sample_title, size = 15);

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)##80:20 train:test ratio
logistic = LogisticRegression()
logistic.fit(X_train,y_train)
y_predict = logistic.predict(X_test)
y_predict = logistic.predict(X_test)

print('Accuracy:',accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

plt.figure(figsize=(4,4))
sb.heatmap(confusion_matrix(y_test,y_predict), annot=True, fmt=".1f", linewidths=.90, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_predict))
plt.title(all_sample_title, size = 15);

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)##75:25 train:test ratio
logistic = LogisticRegression()
logistic.fit(X_train,y_train)
y_predict = logistic.predict(X_test)
y_predict = logistic.predict(X_test)

print('Accuracy:',accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

plt.figure(figsize=(4,4))
sb.heatmap(confusion_matrix(y_test,y_predict), annot=True, fmt=".1f", linewidths=.90, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_predict))
plt.title(all_sample_title, size = 15);

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)##70:30 train:test ratio
logistic = LogisticRegression()
logistic.fit(X_train,y_train)
y_predict = logistic.predict(X_test)
y_predict = logistic.predict(X_test)

print('Accuracy:',accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

plt.figure(figsize=(4,4))
sb.heatmap(confusion_matrix(y_test,y_predict), annot=True, fmt=".1f", linewidths=.90, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_predict))
plt.title(all_sample_title, size = 15);

"""#now decision tree"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)##50:50 train:test ratio
tree=DecisionTreeClassifier(criterion="entropy")
tree.fit(X_train,y_train)
treeprediction=tree.predict(X_test)

print('Accuracy:',accuracy_score(y_test,treeprediction))
print('Classification Report',classification_report(y_test,treeprediction))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)##80:20 train:test ratio
tree=DecisionTreeClassifier(criterion="entropy")
tree.fit(X_train,y_train)
treeprediction=tree.predict(X_test)

print('Accuracy:',accuracy_score(y_test,treeprediction))
print('Classification Report',classification_report(y_test,treeprediction))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)##75:25 train:test ratio
tree=DecisionTreeClassifier(criterion="entropy")
tree.fit(X_train,y_train)
treeprediction=tree.predict(X_test)

print('Accuracy:',accuracy_score(y_test,treeprediction))
print('Classification Report',classification_report(y_test,treeprediction))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)##70:30 train:test ratio
tree=DecisionTreeClassifier(criterion="entropy")
tree.fit(X_train,y_train)
treeprediction=tree.predict(X_test)

print('Accuracy:',accuracy_score(y_test,treeprediction))
print('Classification Report',classification_report(y_test,treeprediction))

"""#now naive bayes"""

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5)##50:50 train:test ratio
gnb = GaussianNB()
gnb.fit(X_train,y_train)
y_pred=gnb.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,y_pred))
print('Classification Report',classification_report(y_test,y_pred))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)##80:20 train:test ratio
gnb = GaussianNB()
gnb.fit(X_train,y_train)
y_pred=gnb.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,y_pred))
print('Classification Report',classification_report(y_test,y_pred))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)##75:25 train:test ratio
gnb = GaussianNB()
gnb.fit(X_train,y_train)
y_pred=gnb.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,y_pred))
print('Classification Report',classification_report(y_test,y_pred))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)##70:30 train:test ratio
gnb = GaussianNB()
gnb.fit(X_train,y_train)
y_pred=gnb.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,y_pred))
print('Classification Report',classification_report(y_test,y_pred))

"""#now mlp"""

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.5)##50:50 train:test ratio
MLP = MLPClassifier(max_iter=500, activation='relu')
MLP.fit(X_train,y_train)
prediction = MLP.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,prediction))
print('Classification Report',classification_report(y_test,prediction))

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)##80:20 train:test ratio
MLP = MLPClassifier(max_iter=500, activation='relu')
MLP.fit(X_train,y_train)
prediction = MLP.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,prediction))
print('Classification Report',classification_report(y_test,prediction))

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25)##75:25 train:test ratio
MLP = MLPClassifier(max_iter=500, activation='relu')
MLP.fit(X_train,y_train)
prediction = MLP.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,prediction))
print('Classification Report',classification_report(y_test,prediction))

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)##70:30 train:test ratio
MLP = MLPClassifier(max_iter=500, activation='relu')
MLP.fit(X_train,y_train)
prediction = MLP.predict(X_test)

print("Accuracy is :",accuracy_score(y_test,prediction))
print('Classification Report',classification_report(y_test,prediction))

"""#now KNN classification"""

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5)##50:50 train:test ratio
neighbors = np.arange(1,25)
train_accuracy =np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i,k in enumerate(neighbors):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    train_accuracy[i] = knn.score(X_train, y_train)
    test_accuracy[i] = knn.score(X_test, y_test)

plt.title('K-nearest neighbors')
plt.plot(neighbors, test_accuracy, label='Testing Accuracy')
plt.plot(neighbors, train_accuracy, label='Training accuracy')
plt.legend()
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.show()

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train,y_train)
knn.score(X_test,y_test)

y_predict = knn.predict(X_test)
print("Accuracy is :",accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)##80:20 train:test ratio
neighbors = np.arange(1,25)
train_accuracy =np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i,k in enumerate(neighbors):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    train_accuracy[i] = knn.score(X_train, y_train)
    test_accuracy[i] = knn.score(X_test, y_test)

plt.title('K-nearest neighbors')
plt.plot(neighbors, test_accuracy, label='Testing Accuracy')
plt.plot(neighbors, train_accuracy, label='Training accuracy')
plt.legend()
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.show()

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train,y_train)
knn.score(X_test,y_test)

y_predict = knn.predict(X_test)
print("Accuracy is :",accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)##75:25 train:test ratio
neighbors = np.arange(1,25)
train_accuracy =np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i,k in enumerate(neighbors):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    train_accuracy[i] = knn.score(X_train, y_train)
    test_accuracy[i] = knn.score(X_test, y_test)

plt.title('K-nearest neighbors')
plt.plot(neighbors, test_accuracy, label='Testing Accuracy')
plt.plot(neighbors, train_accuracy, label='Training accuracy')
plt.legend()
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.show()

knn = KNeighborsClassifier(n_neighbors=6)
knn.fit(X_train,y_train)
knn.score(X_test,y_test)

y_predict = knn.predict(X_test)
print("Accuracy is :",accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)##50:50 train:test ratio
neighbors = np.arange(1,25)
train_accuracy =np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i,k in enumerate(neighbors):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    train_accuracy[i] = knn.score(X_train, y_train)
    test_accuracy[i] = knn.score(X_test, y_test)

plt.title('K-nearest neighbors')
plt.plot(neighbors, test_accuracy, label='Testing Accuracy')
plt.plot(neighbors, train_accuracy, label='Training accuracy')
plt.legend()
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.show()

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train,y_train)
knn.score(X_test,y_test)

y_predict = knn.predict(X_test)
print("Accuracy is :",accuracy_score(y_test,y_predict))
print('Classification Report',classification_report(y_test,y_predict))

"""#among all the machine learning algorithms used decision tree gives with the high accuracy of 0.9957"""